{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iryrpG9AvX0a",
        "outputId": "83f4dc8e-3ec2-4dd8-b76f-11db622e7604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from pt-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Processando documento 1/30...\n",
            "Processando documento 2/30...\n",
            "Processando documento 3/30...\n",
            "Processando documento 4/30...\n",
            "Processando documento 5/30...\n",
            "Processando documento 6/30...\n",
            "Processando documento 7/30...\n",
            "Processando documento 8/30...\n",
            "Processando documento 9/30...\n",
            "Processando documento 10/30...\n",
            "Processando documento 11/30...\n",
            "Processando documento 12/30...\n",
            "Processando documento 13/30...\n",
            "Processando documento 14/30...\n",
            "Processando documento 15/30...\n",
            "Processando documento 16/30...\n",
            "Processando documento 17/30...\n",
            "Processando documento 18/30...\n",
            "Processando documento 19/30...\n",
            "Processando documento 20/30...\n",
            "Processando documento 21/30...\n",
            "Processando documento 22/30...\n",
            "Processando documento 23/30...\n",
            "Processando documento 24/30...\n",
            "Processando documento 25/30...\n",
            "Processando documento 26/30...\n",
            "Processando documento 27/30...\n",
            "Processando documento 28/30...\n",
            "Processando documento 29/30...\n",
            "Processando documento 30/30...\n",
            "\n",
            "Processamento concluído! Arquivo 'corpus_completo.json' gerado com sucesso.\n",
            "Documentos processados: 30\n",
            "Documentos com erro: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!pip install gdown PyPDF2 spacy\n",
        "!python -m spacy download pt_core_news_sm\n",
        "\n",
        "import gdown\n",
        "import json\n",
        "import PyPDF2\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "# Carregar o modelo de português do spaCy\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "# Lista de IDs dos arquivos\n",
        "file_ids = [\n",
        "    \"1XschuJb1UDyozZpW-xZei7otOdOdpAmF\",\n",
        "    \"1-RFpN7QFepPAUecHXUqPAMhfffBztM6x\",\n",
        "    \"1wth9iGEtAzPcBH68KY9N5Y0QMDJ5n3B8\",\n",
        "    \"11MXRfsuBsDaTyqirMCMaUYrmJca9x0eI\",\n",
        "    \"19LRt4ZV5of8Dqv8sw39NbduIUYQLrDSL\",\n",
        "    \"1P3Jou4cRrUMvI6IEMx2uubplguKmthm6\",\n",
        "    \"1BALTGIPAmfYvMqxe0Vajnf_6KRa_Q9vW\",\n",
        "    \"17DSZA17USbsvqE-kmDb8R0v4dyJaqgZb\",\n",
        "    \"1AFPqaYgGu_PZakm5R8_S1pBkbnhu7HJ1\",\n",
        "    \"11zJcFbm-UrtSBDSOCGyt4UTnipRmykB4\",\n",
        "    \"1Wn84a43rimFMilx5tz4UJKrTmxwHlzR2\",\n",
        "    \"1CJ_9iHaQgTymhl-q1FuVmUjB0Fokj5Vi\",\n",
        "    \"1uc2gBvbu8rwCpCoDOvGjmt5WWOu1Z7nb\",\n",
        "    \"1HwspF-Xgeu1oV-59HiXCYuaeaNaf21yU\",\n",
        "    \"1Hm7DOXhFFBMIc74IvOtZqU9RKT7qNcHK\",\n",
        "    \"1xWxy-ki2ipwDLYD4I0fzWtT9x9NNo3Zh\",\n",
        "    \"1piBg1AidZjDnsPl_4thMxUELEklyo2t4\",\n",
        "    \"18ge6TWOoFS8sVLWII8klOwliU7HA6NUA\",\n",
        "    \"1kU7-hrzRkHW_y6X1rmS-VZV882GhYb86\",\n",
        "    \"1TlpV42qfBf-lO76iymx4OQRFE03nV0qJ\",\n",
        "    \"1dgG2Qf4MkSoD5hwx6SwPGEzvHjA1Z55_\",\n",
        "    \"1lIXTptTKJKQm8sjmX1SEzRW-3hufpNS_\",\n",
        "    \"1NHPtt3BcxOgzKNo6K7YcECfsr1WWg8_J\",\n",
        "    \"1Pl_PRb5JiPcQHvEpU41UJTIDawm5wIPo\",\n",
        "    \"1NG-lhZBV3nf7iozy4-eI4rhjPcZGHZsq\",\n",
        "    \"1H_7zQVV12wU-c0H-HCyK-SsMWaPgUVKP\",\n",
        "    \"1X-LOU4xJ3t3maaTUtl7hLJ4Uzi-kw6kT\",\n",
        "    \"1gWGDD-PORqATDIW_kpXTCknXsrLm1hVi\",\n",
        "    \"15cc_iQgVPkAx8foLe__Xtp_RYRnB6aSr\",\n",
        "    \"1zLZxSxO1J7XpztujVAH4wuRClPSQyBvK\"\n",
        "]\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def process_text(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Métricas básicas\n",
        "    num_sentencas = len(list(doc.sents))\n",
        "    num_tokens = len(doc)\n",
        "\n",
        "    # Tokenização e lematização\n",
        "    tokens = [token.text for token in doc]\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    pos_tags = [token.pos_ for token in doc]\n",
        "\n",
        "    # Frequência de tokens\n",
        "    freq_tokens = Counter(tokens)\n",
        "    top10_tokens = freq_tokens.most_common(10)\n",
        "    down10_tokens = freq_tokens.most_common()[-10:]\n",
        "\n",
        "    # Contagem de classes gramaticais\n",
        "    classes_gramaticais = {\n",
        "        'NOUN': 0, 'VERB': 0, 'ADP': 0, 'ADJ': 0, 'ADV': 0,\n",
        "        'PRON': 0, 'DET': 0, 'CCONJ': 0, 'NUM': 0, 'PROPN': 0\n",
        "    }\n",
        "\n",
        "    for token in doc:\n",
        "        if token.pos_ in classes_gramaticais:\n",
        "            classes_gramaticais[token.pos_] += 1\n",
        "\n",
        "    # Análise de dependências\n",
        "    dependencias = [(token.text, token.dep_, token.head.text) for token in doc]\n",
        "\n",
        "    return {\n",
        "        \"estatisticas\": {\n",
        "            \"num_sentencas\": num_sentencas,\n",
        "            \"num_tokens\": num_tokens,\n",
        "            \"tokens_por_sentenca\": num_tokens/num_sentencas if num_sentencas > 0 else 0,\n",
        "            \"top10_tokens\": [{\"token\": t[0], \"frequencia\": t[1]} for t in top10_tokens],\n",
        "            \"down10_tokens\": [{\"token\": t[0], \"frequencia\": t[1]} for t in down10_tokens],\n",
        "            \"classes_gramaticais\": classes_gramaticais,\n",
        "            \"num_substantivos\": classes_gramaticais['NOUN'],\n",
        "            \"num_verbos\": classes_gramaticais['VERB'],\n",
        "            \"num_preposicoes\": classes_gramaticais['ADP']\n",
        "        },\n",
        "        \"analise_linguistica\": {\n",
        "            \"tokens\": tokens,\n",
        "            \"lemmas\": lemmas,\n",
        "            \"pos_tags\": pos_tags,\n",
        "            \"dependencias\": [{\n",
        "                \"token\": d[0],\n",
        "                \"relacao\": d[1],\n",
        "                \"governante\": d[2]\n",
        "            } for d in dependencias]\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Dicionário principal para armazenar todos os resultados\n",
        "resultado_final = {\n",
        "    \"documentos_processados\": [],\n",
        "    \"estatisticas_consolidadas\": {},\n",
        "    \"documentos_com_erro\": []\n",
        "}\n",
        "\n",
        "# Processar todos os arquivos\n",
        "for i, file_id in enumerate(file_ids):\n",
        "    try:\n",
        "        print(f\"Processando documento {i+1}/{len(file_ids)}...\")\n",
        "\n",
        "        # Baixar o arquivo PDF\n",
        "        pdf_path = f\"/content/doc_{i+1}.pdf\"\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={file_id}\", pdf_path, quiet=True)\n",
        "\n",
        "        # Extrair e processar texto\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        resultados = process_text(text)\n",
        "\n",
        "        # Adicionar ao resultado final\n",
        "        resultado_final[\"documentos_processados\"].append({\n",
        "            \"id\": file_id,\n",
        "            \"nome_arquivo\": f\"doc_{i+1}.pdf\",\n",
        "            \"estatisticas\": resultados[\"estatisticas\"],\n",
        "            \"analise_linguistica\": {\n",
        "                \"num_tokens\": len(resultados[\"analise_linguistica\"][\"tokens\"]),\n",
        "                \"num_lemas\": len(resultados[\"analise_linguistica\"][\"lemmas\"]),\n",
        "                \"num_dependencias\": len(resultados[\"analise_linguistica\"][\"dependencias\"])\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro no documento {i+1}: {str(e)}\")\n",
        "        resultado_final[\"documentos_com_erro\"].append({\n",
        "            \"id\": file_id,\n",
        "            \"erro\": str(e)\n",
        "        })\n",
        "\n",
        "# Calcular estatísticas consolidadas\n",
        "if resultado_final[\"documentos_processados\"]:\n",
        "    docs_validos = resultado_final[\"documentos_processados\"]\n",
        "\n",
        "    estatisticas = {\n",
        "        \"total_documentos\": len(docs_validos),\n",
        "        \"total_sentencas\": sum(d[\"estatisticas\"][\"num_sentencas\"] for d in docs_validos),\n",
        "        \"total_tokens\": sum(d[\"estatisticas\"][\"num_tokens\"] for d in docs_validos),\n",
        "        \"media_sentencas_por_doc\": sum(d[\"estatisticas\"][\"num_sentencas\"] for d in docs_validos)/len(docs_validos),\n",
        "        \"media_tokens_por_doc\": sum(d[\"estatisticas\"][\"num_tokens\"] for d in docs_validos)/len(docs_validos),\n",
        "        \"total_substantivos\": sum(d[\"estatisticas\"][\"num_substantivos\"] for d in docs_validos),\n",
        "        \"total_verbos\": sum(d[\"estatisticas\"][\"num_verbos\"] for d in docs_validos),\n",
        "        \"total_preposicoes\": sum(d[\"estatisticas\"][\"num_preposicoes\"] for d in docs_validos),\n",
        "        \"top10_tokens_geral\": Counter(\n",
        "            [item[\"token\"] for doc in docs_validos\n",
        "             for item in doc[\"estatisticas\"][\"top10_tokens\"]]\n",
        "        ).most_common(10)\n",
        "    }\n",
        "\n",
        "    resultado_final[\"estatisticas_consolidadas\"] = estatisticas\n",
        "\n",
        "# Salvar resultado final em um único arquivo JSON\n",
        "with open('corpus_completo.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(resultado_final, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"\\nProcessamento concluído! Arquivo 'corpus_completo.json' gerado com sucesso.\")\n",
        "print(f\"Documentos processados: {len(resultado_final['documentos_processados'])}\")\n",
        "print(f\"Documentos com erro: {len(resultado_final['documentos_com_erro'])}\")\n",
        "\n"
      ]
    }
  ]
}