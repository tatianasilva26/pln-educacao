{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import gdown\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import numpy as np\n",
        "import json\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "id": "Dum_Pxj2KMmg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ID do arquivo do Drive (JSON do corpus final)\n",
        "file_id = \"1ej2uGwFvjeIoUgL6c_aem2348yYzLtIZ\"  # https://drive.google.com/file/d/1ej2uGwFvjeIoUgL6c_aem2348yYzLtIZ/view?usp=drive_link\n",
        "\n",
        "# Baixar o arquivo\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"/content/corpus_SBIE.json\", quiet=False)\n",
        "\n",
        "# Carregar o JSON\n",
        "with open('/content/corpus_SBIE.json', 'r', encoding='utf-8') as f:\n",
        "    corpus = json.load(f)\n",
        "\n",
        "print(f\"âœ… Corpus carregado! NÃºmero de artigos: {len(corpus)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TclmXlI5KJNJ",
        "outputId": "fa8a63ee-4f97-45aa-f4b6-9a5db35ba52d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ej2uGwFvjeIoUgL6c_aem2348yYzLtIZ\n",
            "To: /content/corpus_SBIE.json\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.2M/13.2M [00:00<00:00, 65.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Corpus carregado! NÃºmero de artigos: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPHhcdPSKG49"
      },
      "outputs": [],
      "source": [
        "#sem preprocessamento\n",
        "# 1. Carregar o corpus\n",
        "with open(\"/content/corpus_SBIE.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    corpus = json.load(f)\n",
        "\n",
        "# 2. Obter os textos (limitar a 3 ou 5 documentos curtos para visualizaÃ§Ã£o clara)\n",
        "documentos = [art[\"artigo_completo_PT\"] for art in corpus[:30]]  # puedes ajustar [:5]\n",
        "\n",
        "# 3. ONE-HOT ENCODING\n",
        "onehot = CountVectorizer(binary=True)\n",
        "onehot_matrix = onehot.fit_transform(documentos).toarray()\n",
        "print(\"ðŸ”¹ One-Hot Encoding (presenÃ§a binÃ¡ria)\")\n",
        "print(onehot_matrix)\n",
        "print(onehot.get_feature_names_out())\n",
        "\n",
        "# 4. BAG-OF-WORDS\n",
        "bow = CountVectorizer()\n",
        "bow_matrix = bow.fit_transform(documentos).toarray()\n",
        "print(\"\\nðŸ”¹ Bag-of-Words (frequÃªncia bruta)\")\n",
        "print(bow_matrix)\n",
        "print(bow.get_feature_names_out())\n",
        "\n",
        "\n",
        "# 5. TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(documentos).toarray()\n",
        "print(\"\\nðŸ”¹ TF-IDF\")\n",
        "print(np.round(tfidf_matrix, 3))\n",
        "print(tfidf.get_feature_names_out())\n",
        "#print(TfidfVectorizer.get_feature_names_out())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar stopwords se necessÃ¡rio\n",
        "nltk.download('stopwords')\n",
        "stopwords_pt = stopwords.words('portuguese')\n",
        "\n",
        "# 1. Carregar o corpus\n",
        "with open(\"/content/corpus_SBIE.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    corpus = json.load(f)\n",
        "\n",
        "# 2. Selecionar os textos\n",
        "documentos = [art[\"artigo_completo_PT\"] for art in corpus[:30]]\n",
        "\n",
        "# 3. PrÃ©-processamento simples\n",
        "documentos_preprocessados = [re.sub(r'[^\\w\\s]', '', doc.lower()) for doc in documentos]\n",
        "\n",
        "# 4. One-Hot Encoding\n",
        "print(\"ðŸ”¹ One-Hot Encoding (presenÃ§a binÃ¡ria)\")\n",
        "onehot_vectorizer = CountVectorizer(binary=True, stop_words=stopwords_pt)\n",
        "onehot_matrix = onehot_vectorizer.fit_transform(documentos_preprocessados).toarray()\n",
        "print(onehot_matrix[:5, :10])  # Mostra as 5 primeiras linhas e 10 primeiras colunas\n",
        "print(onehot_vectorizer.get_feature_names_out()[:10])\n"
      ],
      "metadata": {
        "id": "SgjSCwoVPQ3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar as stopwords em portuguÃªs\n",
        "nltk.download('stopwords')\n",
        "stopwords_pt = stopwords.words('portuguese')\n",
        "\n",
        "# 1. Carregar o corpus\n",
        "with open(\"/content/corpus_SBIE.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    corpus = json.load(f)\n",
        "\n",
        "# 2. Selecionar os textos (ex: 30 artigos)\n",
        "documentos = [art[\"artigo_completo_PT\"] for art in corpus[:30]]\n",
        "\n",
        "# 3. PrÃ©-processamento: minÃºsculas, remove nÃºmeros, pontuaÃ§Ã£o e stopwords\n",
        "def preprocessar(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'\\d+', '', texto)\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "    texto = re.sub(r'\\s+', ' ', texto)\n",
        "    return texto\n",
        "\n",
        "documentos_limpos = [preprocessar(doc) for doc in documentos]\n",
        "\n",
        "# ðŸ”¹ One-Hot Encoding (presenÃ§a binÃ¡ria)\n",
        "print(\"ðŸ”¹ One-Hot Encoding (presenÃ§a binÃ¡ria)\")\n",
        "onehot = CountVectorizer(binary=True, stop_words=stopwords_pt, min_df=2)\n",
        "onehot_matrix = onehot.fit_transform(documentos_limpos).toarray()\n",
        "print(onehot_matrix[:5, :10])  # Exibe parte da matriz\n",
        "print(onehot.get_feature_names_out()[:10],\"...\")\n",
        "\n",
        "# ðŸ”¹ Bag-of-Words (frequÃªncia bruta)\n",
        "print(\"\\nðŸ”¹ Bag-of-Words (frequÃªncia bruta)\")\n",
        "bow = CountVectorizer(stop_words=stopwords_pt, min_df=2)\n",
        "bow_matrix = bow.fit_transform(documentos_limpos).toarray()\n",
        "print(bow_matrix[:5, :10])  # Exibe parte da matriz\n",
        "print(bow.get_feature_names_out()[:10],\"...\")\n",
        "\n",
        "# ðŸ”¹ TF-IDF\n",
        "print(\"\\nðŸ”¹ TF-IDF (Term Frequency - Inverse Document Frequency)\")\n",
        "tfidf = TfidfVectorizer(stop_words=stopwords_pt, min_df=2)\n",
        "tfidf_matrix = tfidf.fit_transform(documentos_limpos).toarray()\n",
        "print(np.round(tfidf_matrix[:5, :10], 3))  # Exibe parte da matriz arredondada\n",
        "print(tfidf.get_feature_names_out()[:10],\"...\")\n"
      ],
      "metadata": {
        "id": "0RJjOfQzP3C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“Œ NÃºmero de palavras no vocabulÃ¡rio (One-Hot):\", len(onehot.get_feature_names_out()))\n",
        "print(\"ðŸ“Œ NÃºmero de palavras no vocabulÃ¡rio (BoW):\", len(bow.get_feature_names_out()))\n",
        "print(\"ðŸ“Œ NÃºmero de palavras no vocabulÃ¡rio (TF-IDF):\", len(tfidf.get_feature_names_out()))\n"
      ],
      "metadata": {
        "id": "DKJAvRh-QE4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar outras colunas (por exemplo, de 10 a 20)\n",
        "print(onehot_matrix[:, 10:20])\n",
        "print(bow_matrix[:, 10:20])\n",
        "print(tfidf_matrix[:, 10:20])\n"
      ],
      "metadata": {
        "id": "aZht52HMQTRG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}